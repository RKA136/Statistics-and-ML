{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c4894e",
   "metadata": {},
   "source": [
    "# Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef11c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system manangement\n",
    "import time, psutil, os\n",
    "\n",
    "# Mathematical functions\n",
    "import math\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8fbaf3",
   "metadata": {},
   "source": [
    "# Loading files\n",
    "Keep in mind I am only loading the training.zip here and then having a 80:20 split for train and test. One might as well also use the test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab68e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"training.zip\", compression='zip')\n",
    "df_train.head()\n",
    "df_train[\"Label\"] = df_train[\"Label\"].map({\"s\": 1, \"b\": 0})\n",
    "\n",
    "df_train_signal = df_train[df_train.Label == 1]\n",
    "df_train_background = df_train[df_train.Label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a24b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_train.drop(columns=['EventId', 'Label', 'Weight']).astype(float))\n",
    "y = np.array(df_train['Label'])\n",
    "X=X[:15000]\n",
    "y=y[:15000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407772d7",
   "metadata": {},
   "source": [
    "# Basic SVM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50f5e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC(probability=True)\n",
    "# clf.fit(X_train, y_train)\n",
    "# confidence = clf.score(X_test, y_test)\n",
    "# print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2857d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 13.6940\n",
      "Epoch 2/10, Loss: 0.7329\n",
      "Epoch 3/10, Loss: 0.7238\n",
      "Epoch 4/10, Loss: 0.7217\n",
      "Epoch 5/10, Loss: 0.7142\n",
      "Epoch 6/10, Loss: 0.6247\n",
      "Epoch 7/10, Loss: 0.6239\n",
      "Epoch 8/10, Loss: 0.6859\n",
      "Epoch 9/10, Loss: 0.6678\n",
      "Epoch 10/10, Loss: 0.5888\n",
      "Model architecture:\n",
      " SimpleDNN(\n",
      "  (hidden): Linear(in_features=30, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Accuracy on test set: 72.47%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(64, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = torch.sigmoid(self.output(x))  # sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleDNN(input_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad() # reset old gradients\n",
    "        outputs = model(batch_X) # forward pass\n",
    "        loss = criterion(outputs, batch_y) # compute loss\n",
    "        loss.backward() # backward pass (autograd computes gradients)\n",
    "        optimizer.step() # update weights\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Model architecture:\\n\", model, \"\\n\")\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3062bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 35.1514\n",
      "Epoch 2/10, Loss: 15.3058\n",
      "Epoch 3/10, Loss: 0.9318\n",
      "Epoch 4/10, Loss: 0.8563\n",
      "Epoch 5/10, Loss: 0.7347\n",
      "Epoch 6/10, Loss: 0.7530\n",
      "Epoch 7/10, Loss: 0.7270\n",
      "Epoch 8/10, Loss: 0.6758\n",
      "Epoch 9/10, Loss: 0.7151\n",
      "Epoch 10/10, Loss: 0.7601\n",
      "Model architecture:\n",
      " SimpleDNN(\n",
      "  (hidden): Linear(in_features=30, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Accuracy on test set: 72.77%\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TwoLayerDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)   # first hidden layer y=x.W^T+b\n",
    "        self.fc2 = nn.Linear(64, 32)          # second hidden layer\n",
    "        self.output = nn.Linear(32, 1)        # output layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.output(x))     # sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleDNN(input_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad() # reset old gradients\n",
    "        outputs = model(batch_X) # forward pass\n",
    "        loss = criterion(outputs, batch_y) # compute loss\n",
    "        loss.backward() # backward pass (autograd computes gradients)\n",
    "        optimizer.step() # update weights\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Model architecture:\\n\", model, \"\\n\")\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a9400",
   "metadata": {},
   "source": [
    "```text\n",
    "Conv1: 7x7, 64, stride=2, padding=3\n",
    "↓\n",
    "BatchNorm\n",
    "↓\n",
    "ReLU\n",
    "↓\n",
    "MaxPool: 3x3, stride=2, padding=1\n",
    "↓\n",
    "+--------------------+\n",
    "| Layer1:             |\n",
    "| [Conv3x3,64 ->      |\n",
    "|  Conv3x3,64] x2     |\n",
    "| Residual blocks      |\n",
    "+--------------------+\n",
    "↓\n",
    "+--------------------+\n",
    "| Layer2:             |\n",
    "| [Conv3x3,128 ->     |\n",
    "|  Conv3x3,128] x2    |\n",
    "| Residual blocks      |\n",
    "| (downsample at first|\n",
    "|  block with stride2)|\n",
    "+--------------------+\n",
    "↓\n",
    "+--------------------+\n",
    "| Layer3:             |\n",
    "| [Conv3x3,256 ->     |\n",
    "|  Conv3x3,256] x2    |\n",
    "| Residual blocks      |\n",
    "| (downsample at first|\n",
    "|  block with stride2)|\n",
    "+--------------------+\n",
    "↓\n",
    "+--------------------+\n",
    "| Layer4:             |\n",
    "| [Conv3x3,512 ->     |\n",
    "|  Conv3x3,512] x2    |\n",
    "| Residual blocks      |\n",
    "| (downsample at first|\n",
    "|  block with stride2)|\n",
    "+--------------------+\n",
    "↓\n",
    "Average Pool (7x7)\n",
    "↓\n",
    "Fully Connected Layer (512 → num_classes, e.g., 1000 for ImageNet)\n",
    "↓\n",
    "Softmax (for classification)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d64d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
